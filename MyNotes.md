## Attention

- Andrej Karpathy: Let's build GPT from scratch — Deep dive into building a mini GPT model in PyTorch, covering tokenization, training loops, and generation. [Reference](https://www.youtube.com/watch?v=eMlx5fFNoYc)
- The Illustrated Transformer — Visual explanation of the Transformer architecture with friendly diagrams and intuition. [Reference](https://jalammar.github.io/illustrated-transformer/)
- Sasha Rush: Attention Is All You Need (Stanford CS25) — Lecture explaining the original Transformer paper with math intuition and history. [Reference](https://www.youtube.com/watch?v=KJtZARuO3JY)
- Yannic Kilcher: Transformer Models Masterclass — Walkthrough of Transformer mechanics, attention, and architecture variations using diagrams. [Reference](https://www.youtube.com/watch?v=bCz4OMemCcA)
- Sebastian Raschka: LLMs in Production — Covers practical considerations for deploying large language models, latency, scaling, and evaluation best practices. [Reference](https://www.youtube.com/watch?v=Q5baLehv5So)
