## Neural Network

- 3Blue1Brown: But What Is a Neural Network? — Intuitive visual introduction to perceptrons, activation functions, and training via gradient descent. [Reference](https://www.youtube.com/watch?v=aircAruvnKk)

## Attention

- Andrej Karpathy: Let's build GPT from scratch — Deep dive into building a mini GPT model in PyTorch, covering tokenization, training loops, and generation. [Reference](https://www.youtube.com/watch?v=eMlx5fFNoYc)
- The Illustrated Transformer — Visual explanation of the Transformer architecture with friendly diagrams and intuition. [Reference](https://jalammar.github.io/illustrated-transformer/)
- Sasha Rush: Attention Is All You Need (Stanford CS25) — Lecture explaining the original Transformer paper with math intuition and history. [Reference](https://www.youtube.com/watch?v=KJtZARuO3JY)
- Yannic Kilcher: Transformer Models Masterclass — Walkthrough of Transformer mechanics, attention, and architecture variations using diagrams. [Reference](https://www.youtube.com/watch?v=bCz4OMemCcA)
- Sebastian Raschka: LLMs in Production — Covers practical considerations for deploying large language models, latency, scaling, and evaluation best practices. [Reference](https://www.youtube.com/watch?v=Q5baLehv5So)


## Reads
- Context Engineering - Short-Term Memory Management with Sessions from OpenAI Agents SDK. [Reference](https://cookbook.openai.com/examples/agents_sdk/session_memory)
- HuggingFace Fineweb [Reference](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1)
- Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations[Reference](https://arxiv.org/abs/2306.08121)



## Examples
- DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation.  [Reference](https://dreambooth.github.io/)
- 