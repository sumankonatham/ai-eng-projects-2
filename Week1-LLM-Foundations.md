## LLM Foundations

This lecture introduces the foundations of LLMs, from pre-training data pipelines to model architectures, evaluation methods, and chatbot system design.

### Learning Objectives
- Understand data collection, cleaning, and tokenization for LLMs
- Learn key architectural concepts (Transformers, GPT, Llama) and text generation methods
- Compare pre-training and post-training approaches, such as SFT and RLHF
- Review evaluation metrics, benchmarks, and human assessment

### Assets
- **Canvas**: Available under Files (icon on the top left). Download and import into an Excalidraw session.

### Links Mentioned
- [AI Index: State of AI in 13 Charts](https://hai.stanford.edu/news/ai-index-state-ai-13-charts)
- [Does Anthropic crawl data from the web, and how can site owners block the crawler?](https://support.anthropic.com/en/articles/8896518-does-anthropic-crawl-data-from-the-web-and-how-can-site-owners-block-the-crawler)
- [GPT-2 paper](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- [Common Crawl](https://commoncrawl.org/)
- [TensorFlow C4](https://www.tensorflow.org/datasets/catalog/c4)
- [Hugging Face C4](https://huggingface.co/datasets/allenai/c4)
- [Dolma summary](https://huggingface.co/papers/2402.00159)
- [Dolma paper](https://arxiv.org/pdf/2402.00159)
- [RefinedWeb](https://arxiv.org/abs/2306.01116)
- [FineWeb](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1)
- [URL filtering blocklist](https://dsi.ut-capitole.fr/blacklists/)
- [BPE visualization](https://process-mining.tistory.com/189)
- [Hugging Face BPE tutorial](https://huggingface.co/learn/llm-course/en/chapter6/5)
- [Hugging Face Llama 3 docs](https://huggingface.co/docs/transformers/en/model_doc/llama3)
- [Tiktokenizer](http://tiktokenizer.vercel.app/)
- [Tiktoken library](https://github.com/openai/tiktoken)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Llama 3 paper](https://arxiv.org/abs/2407.21783)
- [Generation strategies](https://huggingface.co/docs/transformers/en/generation_strategies)
- [How to generate text (Hugging Face blog)](https://huggingface.co/blog/how-to-generate)
- [Instruction tuning datasets](https://huggingface.co/collections/mapama247/instruction-tuning-datasets-65ddec58a16a00a4c84e5cf1)
- [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)
- [Alpaca dataset](https://huggingface.co/datasets/tatsu-lab/alpaca)
